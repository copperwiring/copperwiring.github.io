[{"authors":["admin"],"categories":null,"content":"I am currently a graduate research assistant at Networked Robotics and Sensing Laboratory under the supervision of Prof. Shahram Payandeh at Simon Fraser University, Canada. My work revolves around intersection of computer vision and machine learning where I address the problem of unsupervised tracking using RGB and depth images using depth image sensors. In past, I have worked with some great research teams in India including Helicopter and VTOL Laboratory, IIT Kanpur (supervised by Prof. Abhishek), Samsung IoT Innovation Lab, IIT Delhi (supervised by Prof. Brejesh Lall) and Applied Cognitive Science Lab, IIT Mandi (supervised by Prof. Varun Dutt).\nI am also currently doing an internship at UrtheCast where I am responsible for developing computationally intensive image processing algorithms for large scale satellite data within a cloud-based infrastructure using deep learning.\nI am active member of developer community groups of Vancouver where I run Women in Machine Learning and Data Science meetup, Google Developers Group and Vancouver OpenCV meetup. As a strong proponent of tech and diversity, my involvement goes beyond local community work. I am currently one of the the chairs of Women in Computer Vision workshop co-hosted with CVPR, 2020 and was on the committe of the Women in Machine Learning workshop, 2019.\nIf you have questions about my any of work, feel free to reach out to me via email. I\u0026rsquo;ll be happy to chat!\n","date":1372636800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1372636800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://srishti.dev/author/srishti-yadav/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/srishti-yadav/","section":"authors","summary":"I am currently a graduate research assistant at Networked Robotics and Sensing Laboratory under the supervision of Prof. Shahram Payandeh at Simon Fraser University, Canada. My work revolves around intersection of computer vision and machine learning where I address the problem of unsupervised tracking using RGB and depth images using depth image sensors.","tags":null,"title":"Srishti Yadav","type":"authors"},{"authors":null,"categories":null,"content":"In deep learning, it is not easy to tune hyperparameters for optimal results. If we have 2 parameters (each with 3 prior desirable values), it is an easier problem. We will have possible combinations to try. However, with more parameters, the possible combinations will increase exponentially. For example, for 5 parameters, each with 4 desired values, we will have possible combinations. Manually trying each of them is not a very practical approach.\nhence, the question usually is \u0026ldquo;Which way should I update my hyper-parameter to reduce the loss (i.e. gradients) in order to find the optimal model architecture?\nIdealy, we should come up with an approach :\n where we can search for hyperparameters (hyper-parameter search space) using a distributed compute on the cloud. intelligently optimize which of the possible combinations from the search space will give us the best results. Supports exisitng optimization techniques like Grid Search, Random Search, Bayesian Optmization etc.  Some of the exisiting tools for hyperparamter tuning are:\n RayTune (https://ray.readthedocs.io/en/latest/tune.html) Talos (https://autonomio.github.io/talos) NNI (https://nni.readthedocs.io/en/latest/index.html) Orion (https://orion.readthedocs.io/en/latest/user/pytorch.html#adapting-the-code-for-orion) Sherpa (https://parameter-sherpa.readthedocs.io/en/latest/parallel/parallel-guide.html) TPOT (https://github.com/EpistasisLab/tpot) Hyperopt (https://github.com/hyperopt/hyperopt) AWS Sagemaker Hyperparameter tuning (https://aws.amazon.com/sagemaker/?hp=tile\u0026amp;so-exp=below) Botorch (https://botorch.org/)  Here, we will discuss hyperopt!\nHyperopt is an open-source hyperparameter tuning library written for Python. Hyperopt provides a general API for searching over hyperparameters and model types. Hyperopt offers two tuning algorithms: Random Search and the Bayesian method Tree of Parzen Estimators (TPE). To run hyperopt you define:\n the objective function the parameter space the number of experiments  There are both continuous and categorical methods to describe the parameters.\nLimitation: Hyper-parameter takes a lot of time to tune the parameters if number of trials and number of epocs (iteration of the neural network) are higher (which is desired). Hence, it would be good to explore how to parallelize the tuning work.\n","date":1591040280,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591040280,"objectID":"f1a43b65d43100ada01b052d9aa96095","permalink":"https://srishti.dev/post/2020-06-01-hyperopt/","publishdate":"2020-06-01T12:38:00-07:00","relpermalink":"/post/2020-06-01-hyperopt/","section":"post","summary":"In deep learning, it is not easy to tune hyperparameters for optimal results. If we have 2 parameters (each with 3 prior desirable values), it is an easier problem. We will have possible combinations to try.","tags":"technical","title":"Hyperopt: A tool for parameter tuning","type":"post"},{"authors":null,"categories":null,"content":"When we do machine learning, a lot of time, we use vectors to perform any computation. let us see few examples of vectors we come across any machine learning or dep leaning mathematics:\nExample 1: $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$\nExample 2: (ax^2 + bx + c = 0)\nThe same thing can be done using the traditional method of loops too. Let\u0026rsquo;s see how.\nWe will write a small code to take the dot problem of two numbers. For the vectorized method, we\u0026rsquo;ll use numpy library and for non-vectorized method, we\u0026rsquo;ll use the traditional for loop.\nVectorized Method: import numpy as np import time #We'll create an array of the size 100000 and populate it with random samples from a uniform distribution over [0, 1). #For this purpose, we'l use np.random.rand() #Link: https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.rand.html a = np.random.rand(100000) b = np.random.rand(100000) #We'll compute the time taken to compute the vector dot product tic = time.time() c = np.dot(a,b) toc = time.time() print(c) print(\u0026quot;Vectorized version:\u0026quot; + str(1000*(toc-tic)) + \u0026quot; ms\u0026quot;)  Output:\n25032.80826579146 Vectorized version:5.956172943115234 ms  Non-Vectorized Method: ## Non-Vectorized Version c = 0; tic = 0; toc = 0 #We'll compute the time taken to compute the dot product using for loop tic = time.time() for i in range(100000): c += a[i]*b[i] toc = time.time() print(c) print(\u0026quot;Vectorized version:\u0026quot; + str(1000*(toc-tic)) + \u0026quot; ms\u0026quot;)  Output:\n25032.808265791115 Vectorized version:91.36772155761719 ms  From the outputs, we can see that the for loop takes 20x time than the vectorized method. This difference can be significant if we have large amounts of data where vectorization can save us a lot of computation time. Hence, the need of vectorization!\n","date":1573414680,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573414680,"objectID":"53f1c23bad5cbaa419db65b80887fe1e","permalink":"https://srishti.dev/post/2019-11-10-why-do-we-use-vectorization-in-ml/","publishdate":"2019-11-10T12:38:00-07:00","relpermalink":"/post/2019-11-10-why-do-we-use-vectorization-in-ml/","section":"post","summary":"When we do machine learning, a lot of time, we use vectors to perform any computation. let us see few examples of vectors we come across any machine learning or dep leaning mathematics:","tags":"technical","title":"Vectorization in machine learning","type":"post"},{"authors":null,"categories":null,"content":"In computer vision we keep referring to feature vector, especially when we talk about CNNs. But what exactly is a feature vector and can how can you visualize it? Imagine we have an RGB image is the form as shown below:\nNotice, that the value are unique for each color channel. However, we don’t intend to send out this data to any algorithm in 3 fold i.e. sending for one channel and doing computation, sending for second and so on. This is very unrealistic from computation point of you because our original data (pixel values) are ‘together’ representing the image. Hence, we create what we call a feature vector. We create 1-D column vector with values from these 3 color channels. For instance, we start from Red channel and bread each value row wise till the last value. Next we do the same for Blue channel and lastly for Green channel. This gives us one single column vector representing the original image in the form of, what we call, ‘feature vector’. So, what is the final size of the feature vector? This is important to know the total amount of data we will eventually use to do any computation.\nWhen we see the CNN structure, we see that the architecture is defined usingm x n x 3, in case of RGB images. For example, a CNN architecture of dimension 64 x 64 x 3 will have a feature vector of size 12,288.\nSimple!\n","date":1573190466,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573190466,"objectID":"5e4e134262ccb12133b776e4267ba6c2","permalink":"https://srishti.dev/post/2019-11-07-feature-vector-in-machine-learning/","publishdate":"2019-11-07T22:21:06-07:00","relpermalink":"/post/2019-11-07-feature-vector-in-machine-learning/","section":"post","summary":"In computer vision we keep referring to feature vector, especially when we talk about CNNs. But what exactly is a feature vector and can how can you visualize it? Imagine we have an RGB image is the form as shown below:","tags":"technical","title":"Feature Vector in Machine Learning","type":"post"},{"authors":null,"categories":null,"content":"If you are using Ubuntu subshell in Windows (I use the one available in Microsoft Store), this is for you. There are times, where you may need to access the files saved on your windows in the Linux subshell. All you need to do is mount your drive. You may need to access the subshell via administrative privileges. For example, if you have the file in C: Drive, use the following:\ncd /mnt/c ls  The same can be used to access data from external hard disk too. If the external disk is in D: Drive, the command would simply change to:\ncd /mnt/d ls  ","date":1573028706,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573028706,"objectID":"0e7daaa6bc9c277865aaa45019391998","permalink":"https://srishti.dev/post/2019-11-06-accessing-windows-from-linux/","publishdate":"2019-11-06T01:25:06-07:00","relpermalink":"/post/2019-11-06-accessing-windows-from-linux/","section":"post","summary":"If you are using Ubuntu subshell in Windows (I use the one available in Microsoft Store), this is for you. There are times, where you may need to access the files saved on your windows in the Linux subshell.","tags":"Geekout","title":"Accessing Windows File From Linux Subshell","type":"post"},{"authors":["Srishti Yadav","Julian Straub"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"e0648fd04f9d31643dacbf7fde295a3b","permalink":"https://srishti.dev/publication/example-1-copy-2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example-1-copy-2/","section":"publication","summary":"We introduce Replica, a dataset of 18 highly photo-realistic 3D indoor scene reconstructions at room and building scale. Each scene consists of a dense mesh, high-resolution high-dynamic-range (HDR) textures, per-primitive semantic class and instance information, and planar mirror and glass reflectors.","tags":["Source Themes"],"title":"The Replica Dataset: A Digital Replica of Indoor Spaces","type":"publication"},{"authors":["Srishti Yadav","Julian Straub"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"6bab3cf23c810da2cf9966ff9c5409af","permalink":"https://srishti.dev/publication/example-1-copy/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example-1-copy/","section":"publication","summary":"We introduce Replica, a dataset of 18 highly photo-realistic 3D indoor scene reconstructions at room and building scale. Each scene consists of a dense mesh, high-resolution high-dynamic-range (HDR) textures, per-primitive semantic class and instance information, and planar mirror and glass reflectors.","tags":["Source Themes"],"title":"The Replica Dataset: A Digital Replica of Indoor Spaces","type":"publication"},{"authors":["Srishti Yadav","Julian Straub"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"f2cd2c0007ff7e7d968bddd5b71a1a32","permalink":"https://srishti.dev/publication/example-1/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example-1/","section":"publication","summary":"We introduce Replica, a dataset of 18 highly photo-realistic 3D indoor scene reconstructions at room and building scale. Each scene consists of a dense mesh, high-resolution high-dynamic-range (HDR) textures, per-primitive semantic class and instance information, and planar mirror and glass reflectors.","tags":["Source Themes"],"title":"The Replica Dataset: A Digital Replica of Indoor Spaces","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eb88e37724edbbb3eed2b5078895ec9d","permalink":"https://srishti.dev/post/2019-11-08-nile-rive-dispute/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/2019-11-08-nile-rive-dispute/","section":"post","summary":"","tags":null,"title":"","type":"post"}]